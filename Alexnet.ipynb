{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dasari2023/Code/blob/main/Alexnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaHgpYP9dy0U",
        "outputId": "b57ccc55-b466-4c9d-e992-6e54e187ba36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.13)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import tensorflow\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew4u-SojeJHE",
        "outputId": "268ed350-b0da-4da9-e1c7-0d4e500a4f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCmtCMy0eNN6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.backend import image_data_format\n",
        "from keras.models import Sequential\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from keras.models import Sequential\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D, DepthwiseConv2D, SeparableConv2D\n",
        "from keras.layers import AvgPool2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
        "from keras.constraints import maxnorm\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import copy\n",
        "import random\n",
        "import sys\n",
        "import glob\n",
        "import keras\n",
        "import cv2\n",
        "import csv\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCKJ18byeQzu"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import numpy as np # linear algebra\n",
        "import os # accessing directory structure\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOj3JzVGeVGc"
      },
      "outputs": [],
      "source": [
        "# Distribution graphs (histogram/bar graph) of column data\n",
        "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n",
        "    nunique = df.nunique()\n",
        "    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n",
        "    nRow, nCol = df.shape\n",
        "    columnNames = list(df)\n",
        "    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n",
        "    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n",
        "    for i in range(min(nCol, nGraphShown)):\n",
        "        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n",
        "        columnDf = df.iloc[:, i]\n",
        "        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n",
        "            valueCounts = columnDf.value_counts()\n",
        "            valueCounts.plot.bar()\n",
        "        else:\n",
        "            columnDf.hist()\n",
        "        plt.ylabel('counts')\n",
        "        plt.xticks(rotation = 90)\n",
        "        plt.title(f'{columnNames[i]} (column {i})')\n",
        "    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A5hcTT1eZsr"
      },
      "outputs": [],
      "source": [
        "# Correlation matrix\n",
        "def plotCorrelationMatrix(df, graphWidth):\n",
        "    filename = df.dataframeName\n",
        "    df = df.dropna('columns') # drop columns with NaN\n",
        "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
        "    if df.shape[1] < 2:\n",
        "        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n",
        "        return\n",
        "    corr = df.corr()\n",
        "    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n",
        "    corrMat = plt.matshow(corr, fignum = 1)\n",
        "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
        "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
        "    plt.gca().xaxis.tick_bottom()\n",
        "    plt.colorbar(corrMat)\n",
        "    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX0j4GczefPz"
      },
      "outputs": [],
      "source": [
        "# Scatter and density plots\n",
        "def plotScatterMatrix(df, plotSize, textSize):\n",
        "    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n",
        "    # Remove rows and columns that would lead to df being singular\n",
        "    df = df.dropna('columns')\n",
        "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
        "    columnNames = list(df)\n",
        "    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n",
        "        columnNames = columnNames[:10]\n",
        "    df = df[columnNames]\n",
        "    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n",
        "    corrs = df.corr().values\n",
        "    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n",
        "        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n",
        "    plt.suptitle('Scatter and Density Plot')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBGK3cxtejDC",
        "outputId": "4b10496e-f83d-4b9b-e9da-f62f4811cccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation_models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from segmentation_models)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting image-classifiers==1.0.0 (from segmentation_models)\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting efficientnet==1.0.0 (from segmentation_models)\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.22.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.8.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2023.7.18)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (23.1)\n",
            "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation_models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation_models-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install segmentation_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urD1X-wSemS2",
        "outputId": "66ad9b75-1395-48db-bf9a-cee389e36626"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.2.1 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.2.1\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement keras==2.5 (from versions: 0.2.0, 0.3.0, 0.3.1, 0.3.2, 0.3.3, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.0.5, 1.0.6, 1.0.7, 1.0.8, 1.1.0, 1.1.1, 1.1.2, 1.2.0, 1.2.1, 1.2.2, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.0.5, 2.0.6, 2.0.7, 2.0.8, 2.0.9, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.1.5, 2.1.6, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.2.4, 2.2.5, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.5.0rc0, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0rc3, 2.6.0, 2.7.0rc0, 2.7.0rc2, 2.7.0, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.10.0rc0, 2.10.0rc1, 2.10.0, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0rc3, 2.11.0, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.13.1rc0, 2.13.1rc1, 2.13.1, 2.14.0rc0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for keras==2.5\u001b[0m\u001b[31m\n",
            "\u001b[0mSegmentation Models: using `tf.keras` framework.\n"
          ]
        }
      ],
      "source": [
        "!pip install -U -q segmentation-models\n",
        "!pip install -q tensorflow==2.2.1\n",
        "!pip install -q keras==2.5\n",
        "import os\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "from tensorflow import keras\n",
        "import segmentation_models as sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCZOEAN6epiq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.preprocessing import image\n",
        "import segmentation_models as sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqStlhAHfkq_",
        "outputId": "836dd5c0-106a-48ce-c075-896fda51406b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54\n",
            "27\n",
            "54\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "images_t = glob.glob(\"/content/drive/MyDrive/Dataset/Segmentation/Training/*.jpg\")\n",
        "images_t.sort()\n",
        "images_v = glob.glob(\"/content/drive/MyDrive/Dataset/Segmentation/Testing/*.jpg\")\n",
        "images_v.sort()\n",
        "masks_t = glob.glob(\"/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/*.tif\")\n",
        "masks_t.sort()\n",
        "masks_v = glob.glob(\"/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Testing Set/5. Optic Disc/*.tif\")\n",
        "masks_v.sort()\n",
        "print(len(images_t))\n",
        "print(len(images_v))\n",
        "print(len(masks_t))\n",
        "print(len(masks_v))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNdqwGnbfpVN",
        "outputId": "30579f2b-e600-48a9-89f9-74808ab39f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_01.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_02.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_03.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_04.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_05.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_06.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_07.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_08.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_09.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_10.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_11.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_12.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_13.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_14.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_15.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_16.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_17.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_18.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_19.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_20.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_21.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_22.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_23.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_24.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_25.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_26.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_27.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_28.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_29.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_30.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_31.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_32.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_33.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_34.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_35.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_36.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_37.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_38.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_39.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_40.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_41.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_42.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_43.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_44.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_45.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_46.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_47.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_48.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_49.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_50.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_51.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_52.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_53.jpg\n",
            "/content/drive/MyDrive/Dataset/Segmentation/Training/IDRiD_54.jpg\n"
          ]
        }
      ],
      "source": [
        "for x in images_t:\n",
        "    print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc8U3TDNfs4P",
        "outputId": "d3cb10ef-07c7-41aa-9c9f-73ab9b2cfeff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_01_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_02_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_03_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_04_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_05_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_06_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_07_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_08_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_09_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_10_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_11_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_12_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_13_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_14_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_15_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_16_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_17_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_18_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_19_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_20_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_21_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_22_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_23_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_24_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_25_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_26_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_27_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_28_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_29_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_30_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_31_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_32_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_33_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_34_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_35_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_36_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_37_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_38_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_39_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_40_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_41_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_42_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_43_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_44_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_45_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_46_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_47_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_48_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_49_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_50_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_51_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_52_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_53_OD.tif\n",
            "/content/drive/MyDrive/Dataset/Segmentation/All Segmentation Groundtruths/Training Set/5. Optic Disc/IDRiD_54_OD.tif\n"
          ]
        }
      ],
      "source": [
        "for x in masks_t:\n",
        "    print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "pr5WrjHJfweS",
        "outputId": "fec123ca-c559-4bd2-caa9-d6f40e6f2c3d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "image_t=[]\n",
        "image_v=[]\n",
        "mask_t=[]\n",
        "mask_v=[]\n",
        "for x in images_t:\n",
        "  im=cv2.imread(x,cv2.IMREAD_COLOR)\n",
        "  im=cv2.resize(im,(512,512))\n",
        "  image_t.append(im)\n",
        "for x in images_v:\n",
        "  im=cv2.imread(x,cv2.IMREAD_COLOR)\n",
        "  im=cv2.resize(im,(512,512))\n",
        "  image_v.append(im)\n",
        "for y in masks_t:\n",
        "  ma=cv2.imread(y,cv2.IMREAD_GRAYSCALE)\n",
        "  ma=cv2.resize(ma,(512,512),interpolation = cv2.INTER_NEAREST)\n",
        "  plt.imshow(ma)\n",
        "  mask_t.append(ma)\n",
        "for y in masks_v:\n",
        "  ma=cv2.imread(y,cv2.IMREAD_GRAYSCALE)\n",
        "  ma=cv2.resize(ma,(512,512),interpolation = cv2.INTER_NEAREST)\n",
        "  plt.imshow(ma)\n",
        "  mask_v.append(ma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwo_J34Sf0kY",
        "outputId": "2e5ec1a0-22c4-44ae-d1b4-bad85b33ae5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54 54\n",
            "(54, 512, 512, 3)\n",
            "(54, 512, 512, 1)\n",
            "[ 0. 76.]\n",
            "(54, 512, 512, 1)\n"
          ]
        }
      ],
      "source": [
        "print(len(image_t),len(mask_t))\n",
        "img_array_t=np.array(image_t)\n",
        "mask_array_t=np.array(mask_t)\n",
        "mask_array_t=np.expand_dims(mask_array_t,axis=-1)\n",
        "img_array_v=np.array(image_v)\n",
        "mask_array_v=np.array(mask_v)\n",
        "mask_array_v=np.expand_dims(mask_array_v,axis=-1)\n",
        "mask_array_t=mask_array_t.astype(np.float32)\n",
        "mask_array_v=mask_array_v.astype(np.float32)\n",
        "print(img_array_t.shape)\n",
        "print(mask_array_t.shape)\n",
        "print((np.unique(mask_array_t)))\n",
        "print(mask_array_t.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHGcAAhIf5Hi",
        "outputId": "73fd9a8c-1d3b-4246-bb98-40b21d1844c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1.]\n",
            "[0. 1.]\n"
          ]
        }
      ],
      "source": [
        "a=np.where(mask_array_t==76)\n",
        "mask_array_t[a]=1\n",
        "print(np.unique(mask_array_t))\n",
        "b=np.where(mask_array_v==76)\n",
        "mask_array_v[b]=1\n",
        "print(np.unique(mask_array_v))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "Nc776Mb5f8fN",
        "outputId": "a95060e6-5a9b-4d6f-db41-87f60dbf66a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c569ec031f0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(mask_array_t[20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdPSJl-4f_eZ"
      },
      "outputs": [],
      "source": [
        "x_train=list()\n",
        "y_train=list()\n",
        "#dgtest = glob.glob('/content/drive/MyDrive/Dataset/Disease Grading/Testing/*.jpg')\n",
        "dgtrain =glob.glob('/content/drive/MyDrive/Dataset/Disease Grading/Training/*.jpg')\n",
        "ltrain =glob.glob('/content/drive/MyDrive/Dataset/Localization/Training/*.jpg')\n",
        "strain =glob.glob('/content/drive/MyDrive/Dataset/Segmentation/Training/*.jpg')\n",
        "for i in dgtrain:\n",
        "    img=cv2.imread(i,1)\n",
        "    img=cv2.resize(img,(150,150))\n",
        "    img=np.float32(img)\n",
        "    img/=255.0\n",
        "    img = img.reshape(150, 150, 3)\n",
        "    x_train.append(img)\n",
        "    y_train.append(0)\n",
        "for j in ltrain:\n",
        "    img=cv2.imread(j,1)\n",
        "    img=cv2.resize(img,(150,150))\n",
        "    img=np.float32(img)\n",
        "    img/=255.0\n",
        "    img = img.reshape(150, 150, 3)\n",
        "    x_train.append(img)\n",
        "    y_train.append(1)\n",
        "for k in strain:\n",
        "    img=cv2.imread(k,1)\n",
        "    img=cv2.resize(img,(150,150))\n",
        "    img=np.float32(img)\n",
        "    img/=255.0\n",
        "    img = img.reshape(150, 150, 3)\n",
        "    x_train.append(img)\n",
        "    y_train.append(2)\n",
        "x_train=np.asarray(x_train)\n",
        "y_train=np.asarray(y_train)\n",
        "y_train=to_categorical(y_train)\n",
        "x_train.shape\n",
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgZ6hy6IgD3h"
      },
      "outputs": [],
      "source": [
        "x_test=list()\n",
        "y_test=list()\n",
        "dgtest = glob.glob('/content/drive/MyDrive/Dataset/Disease Grading/Testing/*.jpg')\n",
        "#dgtest =glob.glob('/content/drive/MyDrive/Dataset/Disease Grading/Training/*.jpg')\n",
        "ltest =glob.glob('/content/drive/MyDrive/Dataset/Localization/Testing/*.jpg')\n",
        "stest =glob.glob('/content/drive/MyDrive/Dataset/Segmentation/Testing/*.jpg')\n",
        "for i in dgtest:\n",
        "    img=cv2.imread(i,1)\n",
        "    img=cv2.resize(img,(150,150))\n",
        "    img=np.float32(img)\n",
        "    img/=255.0\n",
        "    img = img.reshape(150, 150, 3)\n",
        "    x_test.append(img)\n",
        "    y_test.append(0)\n",
        "for j in ltest:\n",
        "    img=cv2.imread(j,1)\n",
        "    img=cv2.resize(img,(150,150))\n",
        "    img=np.float32(img)\n",
        "    img/=255.0\n",
        "    img = img.reshape(150, 150, 3)\n",
        "    x_test.append(img)\n",
        "    y_test.append(1)\n",
        "for k in stest:\n",
        "    img=cv2.imread(k,1)\n",
        "    img=cv2.resize(img,(150,150))\n",
        "    img=np.float32(img)\n",
        "    img/=255.0\n",
        "    img = img.reshape(150, 150, 3)\n",
        "    x_test.append(img)\n",
        "    y_test.append(2)\n",
        "x_test=np.asarray(x_test)\n",
        "y_test=np.asarray(y_test)\n",
        "y_test=to_categorical(y_test)\n",
        "x_test.shape\n",
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9cRWDtdgIlc",
        "outputId": "f1acd77a-9597-463e-d2ab-6ad1088d8c07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_35 (Conv2D)          (None, 38, 38, 96)        34944     \n",
            "                                                                 \n",
            " batch_normalization_56 (Bat  (None, 38, 38, 96)       384       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_56 (Activation)  (None, 38, 38, 96)        0         \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 19, 19, 96)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 19, 19, 256)       614656    \n",
            "                                                                 \n",
            " batch_normalization_57 (Bat  (None, 19, 19, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_57 (Activation)  (None, 19, 19, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 10, 10, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 10, 10, 384)       885120    \n",
            "                                                                 \n",
            " batch_normalization_58 (Bat  (None, 10, 10, 384)      1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_58 (Activation)  (None, 10, 10, 384)       0         \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 10, 10, 384)       1327488   \n",
            "                                                                 \n",
            " batch_normalization_59 (Bat  (None, 10, 10, 384)      1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_59 (Activation)  (None, 10, 10, 384)       0         \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 10, 10, 256)       884992    \n",
            "                                                                 \n",
            " batch_normalization_60 (Bat  (None, 10, 10, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_60 (Activation)  (None, 10, 10, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 5, 5, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 4096)              26218496  \n",
            "                                                                 \n",
            " batch_normalization_61 (Bat  (None, 4096)             16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_61 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " batch_normalization_62 (Bat  (None, 4096)             16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_62 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 3)                 12291     \n",
            "                                                                 \n",
            " batch_normalization_63 (Bat  (None, 3)                12        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_63 (Activation)  (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46,797,583\n",
            "Trainable params: 46,778,441\n",
            "Non-trainable params: 19,142\n",
            "_________________________________________________________________\n",
            "8/8 [==============================] - 10s 53ms/step - loss: 1.0961 - accuracy: 0.4421\n",
            "Epoch 1/10\n",
            "28/28 [==============================] - 12s 67ms/step - loss: 1.2235 - accuracy: 0.3148\n",
            "Epoch 2/10\n",
            "28/28 [==============================] - 1s 39ms/step - loss: 1.0917 - accuracy: 0.3477\n",
            "Epoch 3/10\n",
            "28/28 [==============================] - 1s 40ms/step - loss: 1.0663 - accuracy: 0.3920\n",
            "Epoch 4/10\n",
            "28/28 [==============================] - 1s 36ms/step - loss: 1.0385 - accuracy: 0.4182\n",
            "Epoch 5/10\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0077 - accuracy: 0.4670\n",
            "Epoch 6/10\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0020 - accuracy: 0.4273\n",
            "Epoch 7/10\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 0.9904 - accuracy: 0.4318\n",
            "Epoch 8/10\n",
            "28/28 [==============================] - 1s 36ms/step - loss: 0.9710 - accuracy: 0.4568\n",
            "Epoch 9/10\n",
            "28/28 [==============================] - 1s 38ms/step - loss: 0.9585 - accuracy: 0.4489\n",
            "Epoch 10/10\n",
            "28/28 [==============================] - 1s 37ms/step - loss: 0.9531 - accuracy: 0.4364\n"
          ]
        }
      ],
      "source": [
        "# Define the architecture of AlexNet\n",
        "import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)\n",
        "\n",
        "# Create a Sequential model\n",
        "AlexNet = Sequential()\n",
        "\n",
        "# Add the 1st Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=96, input_shape=(150,150,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
        "\n",
        "# Add the 2nd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
        "\n",
        "# Add the 3rd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "# Add the 4th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "# Add the 5th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
        "\n",
        "# Flatten the input\n",
        "AlexNet.add(Flatten())\n",
        "\n",
        "# Add the 1st Fully Connected Layer\n",
        "AlexNet.add(Dense(4096, input_shape=(32,32,1,)))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "# Add the 2nd Fully Connected Layer\n",
        "AlexNet.add(Dense(4096))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "# Add the Output layer\n",
        "AlexNet.add(Dense(3))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('softmax'))\n",
        "AlexNet.summary()\n",
        "# Print the model summary\n",
        "# Compile the AlexNet model with categorical cross-entropy loss, SGD optimizer, and accuracy metric\n",
        "AlexNet.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "AlexNet.evaluate(x_test, y_test, verbose=1)\n",
        "# Train the AlexNet model on the training data, for a total of 20 epochs, with validation data for monitoring performance\n",
        "# X_train_gray_norm and y_train represent the preprocessed and normalized training data\n",
        "# X_validation_gray_norm and y_validation represent the preprocessed and normalized validation data\n",
        "history = AlexNet.fit(x_train, y_train, epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.01,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
      ],
      "metadata": {
        "id": "ERpnnQRtnwfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RzxgwftzkRX",
        "outputId": "d7e87d8f-c00b-4afb-8457-3ff7bfd6e40e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==2.12.*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_ukjWMBzpL9",
        "outputId": "c8ba8f11-bf0a-4e70-cbe2-c4adfc4c1126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.12.* in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (0.4.13)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.*) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.*) (0.41.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.*) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.*) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.*) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.*) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.*) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.*) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.*) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.*) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.*) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.*) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.*) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.*) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.*) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.*) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.*) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.*) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.*) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.*) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.*) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import legacy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.backend import image_data_format\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D, DepthwiseConv2D, SeparableConv2D\n",
        "from keras.layers import AvgPool2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
        "from keras.constraints import maxnorm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import copy\n",
        "import random\n",
        "import sys\n",
        "import csv\n",
        "\n",
        "# client config\n",
        "NUMOFCLIENTS = 5 # number of client(as particles)\n",
        "SELECT_CLIENTS = 0.5 # c\n",
        "EPOCHS = 10 # number of total iteration\n",
        "CLIENT_EPOCHS = 5 # number of each client's iteration\n",
        "BATCH_SIZE = 10 # Size of batches to train on\n",
        "DROP_RATE = 0\n",
        "\n",
        "# model config\n",
        "LOSS = 'categorical_crossentropy' # Loss function\n",
        "NUMOFCLASSES = 10 # Number of classes\n",
        "lr = 0.0025\n",
        "# OPTIMIZER = SGD(lr=0.015, decay=0.01, nesterov=False)\n",
        "OPTIMIZER = legacy.SGD(lr=lr, momentum=0.9, decay=lr/(EPOCHS*CLIENT_EPOCHS), nesterov=False) # lr = 0.015, 67 ~ 69%\n",
        "\n",
        "def write_csv(method_name, list):\n",
        "    file_name = '{name}_CIFAR10_randomDrop_{drop}%_output_C_{c}_LR_{lr}_CLI_{cli}_CLI_EPOCHS_{cli_epoch}_TOTAL_EPOCHS_{epochs}_BATCH_{batch}.csv'\n",
        "    file_name = file_name.format(folder=\"origin_drop\",drop=DROP_RATE, name=method_name, c=SELECT_CLIENTS, lr=lr, cli=NUMOFCLIENTS, cli_epoch=CLIENT_EPOCHS, epochs=EPOCHS, batch=BATCH_SIZE)\n",
        "    f = open(file_name, 'w', encoding='utf-8', newline='')\n",
        "    wr = csv.writer(f)\n",
        "\n",
        "    for l in list:\n",
        "        wr.writerow(l)\n",
        "    f.close()\n",
        "\n",
        "def load_dataset():\n",
        "    # Code for experimenting with CIFAR-10 datasets.\n",
        "    (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "\n",
        "    # Code for experimenting with MNIST datasets.\n",
        "    # (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "    # X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "    # X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "    X_train = X_train / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "\n",
        "    Y_train = to_categorical(Y_train)\n",
        "    Y_test = to_categorical(Y_test)\n",
        "\n",
        "    return (X_train, Y_train), (X_test, Y_test)\n",
        "\n",
        "class Model():\n",
        "\n",
        "    def __init__(self, loss, optimizer, classes=10):\n",
        "        self.loss = loss\n",
        "        self.optimizer = optimizer\n",
        "        self.num_classes = classes\n",
        "\n",
        "    def fl_paper_model(self, train_shape):\n",
        "        model = Sequential()\n",
        "\n",
        "        # 1\n",
        "        model.add(Conv2D(filters=32,kernel_size=(5, 5),padding='same',activation='relu',input_shape=train_shape,kernel_regularizer='l2',))\n",
        "        model.add(Conv2D(filters=32,kernel_size=(5, 5),padding='same',activation='relu',kernel_regularizer='l2',))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "        # 2\n",
        "        model.add(Conv2D(filters=64,kernel_size=(5, 5),padding='same',activation='relu',kernel_regularizer='l2',))\n",
        "        model.add(Conv2D(filters=64,kernel_size=(5, 5),padding='same',activation='relu',kernel_regularizer='l2',))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "        # 3\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(units=512,activation='relu',kernel_regularizer='l2',))\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "        # 4\n",
        "        model.add(Dense(units=self.num_classes,activation='softmax'))\n",
        "        model.compile(loss=self.loss,optimizer=self.optimizer,metrics=['accuracy'])\n",
        "\n",
        "        return model\n",
        "\n",
        "def init_model(train_data_shape):\n",
        "    model = Model(loss=LOSS, optimizer=OPTIMIZER, classes=NUMOFCLASSES)\n",
        "    fl_model = model.fl_paper_model(train_shape=train_data_shape)\n",
        "\n",
        "    return fl_model\n",
        "\n",
        "\n",
        "def client_data_config(x_train, y_train):\n",
        "    client_data = [() for _ in range(NUMOFCLIENTS)] # () for _ in range(NUMOFCLIENTS)\n",
        "    num_of_each_dataset = int(x_train.shape[0] / NUMOFCLIENTS)\n",
        "\n",
        "    for i in range(NUMOFCLIENTS):\n",
        "        split_data_index = []\n",
        "        while len(split_data_index) < num_of_each_dataset:\n",
        "            item = random.choice(range(x_train.shape[0]))\n",
        "            if item not in split_data_index:\n",
        "                split_data_index.append(item)\n",
        "\n",
        "        new_x_train = np.asarray([x_train[k] for k in split_data_index])\n",
        "        new_y_train = np.asarray([y_train[k] for k in split_data_index])\n",
        "\n",
        "        client_data[i] = (new_x_train, new_y_train)\n",
        "\n",
        "    return client_data\n",
        "\n",
        "\n",
        "def fedAVG(server_weight):\n",
        "    avg_weight = np.array(server_weight[0])\n",
        "\n",
        "    if len(server_weight) > 1:\n",
        "        for i in range(1, len(server_weight)):\n",
        "            avg_weight += server_weight[i]\n",
        "\n",
        "    avg_weight = avg_weight / len(server_weight)\n",
        "\n",
        "    return avg_weight\n",
        "\n",
        "\n",
        "def client_update(index, client, now_epoch, avg_weight):\n",
        "    print(\"client {}/{} fitting\".format(index + 1, int(NUMOFCLIENTS * SELECT_CLIENTS)))\n",
        "\n",
        "    if now_epoch != 0:\n",
        "        client.set_weights(avg_weight)\n",
        "\n",
        "    client.fit(client_data[index][0], client_data[index][1],\n",
        "        epochs=CLIENT_EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        verbose=1,\n",
        "        validation_split=0.2,\n",
        "    )\n",
        "\n",
        "    return client\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    (x_train, y_train), (x_test, y_test) = load_dataset()\n",
        "\n",
        "    server_model = init_model(train_data_shape=x_train.shape[1:])\n",
        "    server_model.summary()\n",
        "\n",
        "    client_data = client_data_config(x_train, y_train)\n",
        "    fl_model = []\n",
        "    for i in range(NUMOFCLIENTS):\n",
        "        fl_model.append(init_model(train_data_shape=client_data[i][0].shape[1:]))\n",
        "\n",
        "    avg_weight = np.zeros_like(server_model.get_weights())\n",
        "    server_evaluate_acc = []\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        server_weight = []\n",
        "\n",
        "        selected_num = int(max(NUMOFCLIENTS * SELECT_CLIENTS, 1))\n",
        "        split_data_index = []\n",
        "        while len(split_data_index) < selected_num:\n",
        "            item = random.choice(range(len(fl_model)))\n",
        "            if item not in split_data_index:\n",
        "                split_data_index.append(item)\n",
        "        split_data_index.sort()\n",
        "        selected_model = [fl_model[k] for k in split_data_index]\n",
        "\n",
        "        for index, client in enumerate(selected_model):\n",
        "            recv_model = client_update(index, client, epoch, avg_weight)\n",
        "\n",
        "            rand = random.randint(0,99)\n",
        "            drop_communication = range(DROP_RATE)\n",
        "            if rand not in drop_communication:\n",
        "                server_weight.append(copy.deepcopy(recv_model.get_weights()))\n",
        "\n",
        "        avg_weight = fedAVG(server_weight)\n",
        "\n",
        "        server_model.set_weights(avg_weight)\n",
        "        print(\"server {}/{} evaluate\".format(epoch + 1, EPOCHS))\n",
        "        server_evaluate_acc.append(server_model.evaluate(x_test, y_test, batch_size=BATCH_SIZE, verbose=1))\n",
        "\n",
        "    write_csv(\"FedAvg\", server_evaluate_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D59qmzTszvj-",
        "outputId": "4ba4a8f6-57bb-40af-c555-1a428f6793bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "170498071/170498071 [==============================] - 4s 0us/step\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_40 (Conv2D)          (None, 32, 32, 32)        2432      \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 32, 32, 32)        25632     \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 16, 16, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (None, 16, 16, 64)        51264     \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 16, 16, 64)        102464    \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 512)               2097664   \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,284,586\n",
            "Trainable params: 2,284,586\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client 1/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 9s 8ms/step - loss: 9.4890 - accuracy: 0.2077 - val_loss: 6.9671 - val_accuracy: 0.2325\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 5.3514 - accuracy: 0.2944 - val_loss: 4.2580 - val_accuracy: 0.2840\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 3.4835 - accuracy: 0.3501 - val_loss: 2.9437 - val_accuracy: 0.3690\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 4s 6ms/step - loss: 2.5937 - accuracy: 0.3968 - val_loss: 2.3457 - val_accuracy: 0.3950\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 2.1648 - accuracy: 0.4268 - val_loss: 2.0798 - val_accuracy: 0.4075\n",
            "client 2/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 9.9100 - accuracy: 0.2129 - val_loss: 7.4738 - val_accuracy: 0.2765\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 6.0509 - accuracy: 0.2905 - val_loss: 4.8634 - val_accuracy: 0.3015\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 4.0553 - accuracy: 0.3379 - val_loss: 3.3693 - val_accuracy: 0.3725\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 2.9848 - accuracy: 0.3923 - val_loss: 2.6436 - val_accuracy: 0.4145\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 2.4190 - accuracy: 0.4189 - val_loss: 2.1901 - val_accuracy: 0.4410\n",
            "server 1/10 evaluate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-96f565aed8a3>:125: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  avg_weight = np.array(server_weight[0])\n",
            "<ipython-input-31-96f565aed8a3>:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  avg_weight += server_weight[i]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.5508 - accuracy: 0.1055\n",
            "client 1/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.9718 - accuracy: 0.3940 - val_loss: 1.8780 - val_accuracy: 0.4095\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8135 - accuracy: 0.4396 - val_loss: 1.8256 - val_accuracy: 0.4300\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.7428 - accuracy: 0.4680 - val_loss: 1.7872 - val_accuracy: 0.4310\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.6832 - accuracy: 0.4874 - val_loss: 1.7385 - val_accuracy: 0.4655\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.6638 - accuracy: 0.5035 - val_loss: 1.7118 - val_accuracy: 0.4785\n",
            "client 2/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 5s 5ms/step - loss: 1.9840 - accuracy: 0.3848 - val_loss: 1.7797 - val_accuracy: 0.4550\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.8142 - accuracy: 0.4401 - val_loss: 1.7440 - val_accuracy: 0.4470\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.7423 - accuracy: 0.4635 - val_loss: 1.7435 - val_accuracy: 0.4580\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 1.6910 - accuracy: 0.4843 - val_loss: 1.7235 - val_accuracy: 0.4615\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.6593 - accuracy: 0.5006 - val_loss: 1.7661 - val_accuracy: 0.4815\n",
            "server 2/10 evaluate\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6366 - accuracy: 0.5016\n",
            "client 1/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 1.6280 - accuracy: 0.5052 - val_loss: 1.7937 - val_accuracy: 0.4530\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.5950 - accuracy: 0.5316 - val_loss: 1.6616 - val_accuracy: 0.5005\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.5683 - accuracy: 0.5472 - val_loss: 1.6837 - val_accuracy: 0.5100\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 1.5522 - accuracy: 0.5642 - val_loss: 1.7407 - val_accuracy: 0.5130\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.5373 - accuracy: 0.5938 - val_loss: 1.7540 - val_accuracy: 0.5140\n",
            "client 2/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 1.6212 - accuracy: 0.5105 - val_loss: 1.5640 - val_accuracy: 0.5290\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.5783 - accuracy: 0.5281 - val_loss: 1.6503 - val_accuracy: 0.5090\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.5520 - accuracy: 0.5485 - val_loss: 1.5913 - val_accuracy: 0.5460\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 1.5291 - accuracy: 0.5721 - val_loss: 1.6225 - val_accuracy: 0.5450\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.5117 - accuracy: 0.5970 - val_loss: 1.6354 - val_accuracy: 0.5510\n",
            "server 3/10 evaluate\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.5684 - accuracy: 0.5489\n",
            "client 1/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.5175 - accuracy: 0.5750 - val_loss: 1.6810 - val_accuracy: 0.5310\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.4788 - accuracy: 0.6065 - val_loss: 1.6830 - val_accuracy: 0.5485\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.4594 - accuracy: 0.6334 - val_loss: 1.7481 - val_accuracy: 0.5405\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.4486 - accuracy: 0.6528 - val_loss: 1.7698 - val_accuracy: 0.5490\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.4296 - accuracy: 0.6795 - val_loss: 1.8742 - val_accuracy: 0.5435\n",
            "client 2/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.5031 - accuracy: 0.5851 - val_loss: 1.6501 - val_accuracy: 0.5125\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.4764 - accuracy: 0.6022 - val_loss: 1.5938 - val_accuracy: 0.5755\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.4595 - accuracy: 0.6294 - val_loss: 1.6760 - val_accuracy: 0.5590\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 1.4119 - accuracy: 0.6645 - val_loss: 1.7181 - val_accuracy: 0.5505\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.4211 - accuracy: 0.6764 - val_loss: 1.7412 - val_accuracy: 0.5670\n",
            "server 4/10 evaluate\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6257 - accuracy: 0.5821\n",
            "client 1/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.4561 - accuracy: 0.6475 - val_loss: 1.7650 - val_accuracy: 0.5530\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 4s 6ms/step - loss: 1.4009 - accuracy: 0.6842 - val_loss: 1.8193 - val_accuracy: 0.5565\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.3646 - accuracy: 0.7194 - val_loss: 1.9097 - val_accuracy: 0.5620\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.3557 - accuracy: 0.7433 - val_loss: 2.0317 - val_accuracy: 0.5385\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.3422 - accuracy: 0.7795 - val_loss: 2.1550 - val_accuracy: 0.5355\n",
            "client 2/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.4432 - accuracy: 0.6531 - val_loss: 1.6138 - val_accuracy: 0.5935\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.3911 - accuracy: 0.6892 - val_loss: 1.7713 - val_accuracy: 0.5535\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 4s 6ms/step - loss: 1.3489 - accuracy: 0.7216 - val_loss: 1.8204 - val_accuracy: 0.5730\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.3171 - accuracy: 0.7574 - val_loss: 1.8843 - val_accuracy: 0.5625\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.3046 - accuracy: 0.7805 - val_loss: 1.9542 - val_accuracy: 0.5705\n",
            "server 5/10 evaluate\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7688 - accuracy: 0.5874\n",
            "client 1/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 1.4062 - accuracy: 0.7174 - val_loss: 1.8834 - val_accuracy: 0.5645\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.3216 - accuracy: 0.7670 - val_loss: 2.0410 - val_accuracy: 0.5450\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.2857 - accuracy: 0.8019 - val_loss: 2.1033 - val_accuracy: 0.5575\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 1.2800 - accuracy: 0.8195 - val_loss: 2.1819 - val_accuracy: 0.5490\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.2473 - accuracy: 0.8504 - val_loss: 2.3076 - val_accuracy: 0.5485\n",
            "client 2/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.3918 - accuracy: 0.7224 - val_loss: 1.7436 - val_accuracy: 0.6075\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.3278 - accuracy: 0.7664 - val_loss: 1.8295 - val_accuracy: 0.6050\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.2602 - accuracy: 0.8056 - val_loss: 1.9867 - val_accuracy: 0.5860\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.2370 - accuracy: 0.8310 - val_loss: 2.0225 - val_accuracy: 0.5765\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 1.2400 - accuracy: 0.8372 - val_loss: 2.1006 - val_accuracy: 0.5875\n",
            "server 6/10 evaluate\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9444 - accuracy: 0.5775\n",
            "client 1/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 1.3237 - accuracy: 0.7819 - val_loss: 2.0316 - val_accuracy: 0.5570\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.2500 - accuracy: 0.8253 - val_loss: 2.1239 - val_accuracy: 0.5615\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.2041 - accuracy: 0.8554 - val_loss: 2.2019 - val_accuracy: 0.5460\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 1.1826 - accuracy: 0.8769 - val_loss: 2.3485 - val_accuracy: 0.5540\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.1852 - accuracy: 0.8773 - val_loss: 2.2868 - val_accuracy: 0.5430\n",
            "client 2/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.3180 - accuracy: 0.7780 - val_loss: 1.8614 - val_accuracy: 0.6035\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 1.2387 - accuracy: 0.8301 - val_loss: 1.9933 - val_accuracy: 0.5885\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.1930 - accuracy: 0.8569 - val_loss: 2.0386 - val_accuracy: 0.6050\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.1588 - accuracy: 0.8819 - val_loss: 2.0953 - val_accuracy: 0.5970\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.1453 - accuracy: 0.8944 - val_loss: 2.2344 - val_accuracy: 0.5700\n",
            "server 7/10 evaluate\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9483 - accuracy: 0.5911\n",
            "client 1/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.2568 - accuracy: 0.8156 - val_loss: 2.1444 - val_accuracy: 0.5660\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.1767 - accuracy: 0.8684 - val_loss: 2.2612 - val_accuracy: 0.5635\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.1297 - accuracy: 0.8910 - val_loss: 2.3864 - val_accuracy: 0.5415\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.1258 - accuracy: 0.9005 - val_loss: 2.3040 - val_accuracy: 0.5530\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.1127 - accuracy: 0.9076 - val_loss: 2.4014 - val_accuracy: 0.5495\n",
            "client 2/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.2589 - accuracy: 0.8145 - val_loss: 1.9460 - val_accuracy: 0.6010\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.1427 - accuracy: 0.8709 - val_loss: 2.0064 - val_accuracy: 0.6115\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 4s 6ms/step - loss: 1.1322 - accuracy: 0.8874 - val_loss: 2.1084 - val_accuracy: 0.5970\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.0939 - accuracy: 0.8988 - val_loss: 2.1954 - val_accuracy: 0.5805\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 1.0635 - accuracy: 0.9178 - val_loss: 2.1850 - val_accuracy: 0.5895\n",
            "server 8/10 evaluate\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9912 - accuracy: 0.5946\n",
            "client 1/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 1.1607 - accuracy: 0.8511 - val_loss: 2.0615 - val_accuracy: 0.5810\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.1024 - accuracy: 0.8857 - val_loss: 2.2626 - val_accuracy: 0.5760\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.0721 - accuracy: 0.9081 - val_loss: 2.2639 - val_accuracy: 0.5730\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 1.0575 - accuracy: 0.9131 - val_loss: 2.3285 - val_accuracy: 0.5520\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.0288 - accuracy: 0.9281 - val_loss: 2.3537 - val_accuracy: 0.5715\n",
            "client 2/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 1.1854 - accuracy: 0.8461 - val_loss: 1.9658 - val_accuracy: 0.6115\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.1053 - accuracy: 0.8904 - val_loss: 2.0468 - val_accuracy: 0.6180\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.0417 - accuracy: 0.9164 - val_loss: 2.1405 - val_accuracy: 0.6095\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.0363 - accuracy: 0.9159 - val_loss: 2.1403 - val_accuracy: 0.6020\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.0081 - accuracy: 0.9298 - val_loss: 2.2210 - val_accuracy: 0.5940\n",
            "server 9/10 evaluate\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0380 - accuracy: 0.5847\n",
            "client 1/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 4s 6ms/step - loss: 1.0983 - accuracy: 0.8706 - val_loss: 2.1162 - val_accuracy: 0.5780\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.0449 - accuracy: 0.8984 - val_loss: 2.1689 - val_accuracy: 0.5680\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.0217 - accuracy: 0.9149 - val_loss: 2.3294 - val_accuracy: 0.5445\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.0069 - accuracy: 0.9276 - val_loss: 2.3235 - val_accuracy: 0.5715\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.9737 - accuracy: 0.9388 - val_loss: 2.2587 - val_accuracy: 0.5670\n",
            "client 2/2 fitting\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.1040 - accuracy: 0.8662 - val_loss: 1.9579 - val_accuracy: 0.6145\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.0360 - accuracy: 0.9021 - val_loss: 2.0782 - val_accuracy: 0.6050\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 1.0068 - accuracy: 0.9229 - val_loss: 2.1560 - val_accuracy: 0.5985\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.9812 - accuracy: 0.9319 - val_loss: 2.0846 - val_accuracy: 0.5935\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.9564 - accuracy: 0.9421 - val_loss: 2.1885 - val_accuracy: 0.5980\n",
            "server 10/10 evaluate\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0163 - accuracy: 0.5990\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO19rBu/FwzYSyenw4cQdNp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}